
# XOR MLP

This project is a **Multi-Layer Perceptron (MLP)** implemented from scratch in Python using only the `math` module (no external libraries!). Itâ€™s designed to learn the XOR function â€” a classic demonstration of how neural networks can solve non-linear problems.

---

## ðŸ§  Overview

âœ… **Inputs:** 2  
âœ… **Hidden Layer:** 2 neurons  
âœ… **Output:** 1 neuron  
âœ… **Activation:** Sigmoid  
âœ… **Training:** Gradient Descent with Backpropagation  
âœ… **Data:**  

## ðŸ“œ Example Output
Epoch: 0, Input: 0 0, Target: 0, Predicted: 0.7057, Squared Error: 0.4980  
...  
Epoch: 1900, Input: 1 1, Target: 0, Predicted: 0.0089, Squared Error: 0.0001  
___  
  
Final Result:  
Input: 0 0, Target: 0, Predicted: 0.0003, Squared Error: 0.0000  
Input: 0 1, Target: 1, Predicted: 0.9969, Squared Error: 0.0000  
Input: 1 0, Target: 1, Predicted: 0.9969, Squared Error: 0.0000  
Input: 1 1, Target: 0, Predicted: 0.0018, Squared Error: 0.0000  
Sum of Squared Errors: 0.0000  
